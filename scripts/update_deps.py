import hashlib
import json
import os
import re
import shutil
import sys

import requests


def calculate_sha256(filepath):
    """Calculates the SHA256 hash of a file."""
    hasher = hashlib.sha256()
    with open(filepath, "rb") as f:
        while True:
            chunk = f.read(8192)  # Read in 8KB chunks
            if not chunk:
                break
            hasher.update(chunk)
    return hasher.hexdigest()


def download_file(url, download_path):
    """Downloads a file from a URL with progress."""
    print(f"  Downloading: {url}")
    with requests.get(url, stream=True) as r:
        r.raise_for_status()  # Raise HTTPError for bad responses
        total_size = int(r.headers.get("content-length", 0))
        downloaded_size = 0
        with open(download_path, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                f.write(chunk)
                downloaded_size += len(chunk)
                if total_size > 0:
                    progress = int(50 * downloaded_size / total_size)
                    # Print progress on the same line
                    print(
                        f"\r  [{'=' * progress}{' ' * (50 - progress)}] {downloaded_size}/{total_size} bytes",
                        end="",
                    )
            print("\r" + " " * 80 + "\r", end="")  # Clear progress line after download
        print(f"  Downloaded to: {download_path}")
    return True


def get_current_versions_from_cmake(cmake_filepath):
    """Reads versions from an existing versions.cmake file."""
    current_opencv_version = None
    current_wpilib_version = None

    if os.path.exists(cmake_filepath):
        with open(cmake_filepath, "r") as f:
            content = f.read()
            # Use regex to find the set commands for versions
            opencv_match = re.search(r"set\(OPENCV_VERSION \"(.*?)\"\)", content)
            if opencv_match:
                current_opencv_version = opencv_match.group(1)

            wpilib_match = re.search(r"set\(WPILIB_VERSION \"(.*?)\"\)", content)
            if wpilib_match:
                current_wpilib_version = wpilib_match.group(1)
    return current_opencv_version, current_wpilib_version


def generate_cmake_versions_file(versions_data, cmake_output_filepath):
    """Generates the versions.cmake file from the processed data."""
    with open(cmake_output_filepath, "w") as f:
        f.write("# This file is automatically generated by scripts/update_deps.py\n")
        f.write("# DO NOT EDIT THIS FILE MANUALLY!\n\n")

        # --- OpenCV ---
        # For OpenCV, we only need the version string for the Git tag.
        f.write("# --- OpenCV ---\n")
        f.write(f"set(OPENCV_VERSION \"{versions_data['opencv']['version']}\")\n\n")

        # --- WPILib ---
        f.write("# --- WPILib ---\n")
        f.write(f"set(WPILIB_VERSION \"{versions_data['wpi_libs']['version']}\")\n")
        f.write(
            f"set(WPILIB_MAVEN_BASE_URL \"{versions_data['wpi_libs']['base_maven_url']}\")\n\n"
        )

        architectures = ["x86_64", "arm64"]
        build_types = ["release", "debug"]

        # Binary URLs and Hashes for WPILib
        for comp_name, comp_info in versions_data["wpi_libs"]["components"].items():
            f.write(f"# {comp_name}\n")
            for arch in architectures:
                for build_type in build_types:
                    fetch_name = comp_info["fetch_name_template"].format(
                        arch=arch, type=build_type
                    )
                    if fetch_name in versions_data["hashes"]:  # Ensure hash data exists
                        url_var = f"{comp_name.upper()}_{arch.upper()}_BIN_{build_type.upper()}_URL"
                        hash_var = f"{comp_name.upper()}_{arch.upper()}_BIN_{build_type.upper()}_HASH"

                        f.write(
                            f"set({url_var} \"{versions_data['hashes'][fetch_name]['url']}\")\n"
                        )
                        f.write(
                            f"set({hash_var} \"SHA256={versions_data['hashes'][fetch_name]['hash']}\")\n"
                        )

            # Headers URL and Hash (common for all architectures)
            headers_fetch_name = comp_info["headers_fetch_name"]
            if headers_fetch_name in versions_data["hashes"]:  # Ensure hash data exists
                headers_url_var = f"{comp_name.upper()}_HEADERS_URL"
                headers_hash_var = f"{comp_name.upper()}_HEADERS_HASH"
                f.write(
                    f"set({headers_url_var} \"{versions_data['hashes'][headers_fetch_name]['url']}\")\n"
                )
                f.write(
                    f"set({headers_hash_var} \"SHA256={versions_data['hashes'][headers_fetch_name]['hash']}\")\n"
                )
            f.write("\n")

    print(f"Generated {cmake_output_filepath}")


def main():
    script_dir = os.path.dirname(__file__)
    project_root = os.path.abspath(os.path.join(script_dir, os.pardir))
    versions_json_file = os.path.join(project_root, "versions.json")
    cmake_versions_file = os.path.join(project_root, "third_party", "versions.cmake")
    temp_download_dir = os.path.join(project_root, ".tmp_deps_downloads")

    os.makedirs(temp_download_dir, exist_ok=True)

    try:
        with open(versions_json_file, "r") as f:
            desired_versions_data = json.load(f)
    except FileNotFoundError:
        print(f"Error: {versions_json_file} not found. Please create it.")
        sys.exit(1)
    except json.JSONDecodeError:
        print(f"Error: {versions_json_file} is not valid JSON. Please fix it.")
        sys.exit(1)

    # --- DECISION LOGIC: Check if update is truly needed based on versions ---
    current_opencv_version, current_wpi_version = get_current_versions_from_cmake(
        cmake_versions_file
    )
    desired_opencv_version = desired_versions_data["opencv"]["version"]
    desired_wpi_version = desired_versions_data["wpi_libs"]["version"]

    if (
        os.path.exists(cmake_versions_file)
        and current_opencv_version == desired_opencv_version
        and current_wpi_version == desired_wpi_version
    ):
        print(
            f"--- Dependency versions in versions.cmake match desired versions in versions.json. ---"
        )
        print("--- Skipping downloads and hash generation. ---")
        sys.exit(0)

    print(f"--- Dependency versions mismatch or versions.cmake doesn't exist. ---")
    print(
        f"--- Current: (OpenCV={current_opencv_version}, WPILib={current_wpi_version}) | "
        f"Desired: (OpenCV={desired_opencv_version}, WPILib={desired_wpi_version}). ---"
    )
    print("--- Starting Downloads and Hash Generation for required components. ---")

    # --- OpenCV processing is no longer needed here, as FetchContent handles it. ---
    # The version will be updated in the generation step.

    # --- Process WPILib Components ---
    print("\nProcessing WPILib Components...")
    wpi_version = desired_versions_data["wpi_libs"]["version"]
    wpi_base_maven_url = desired_versions_data["wpi_libs"]["base_maven_url"]
    architectures = {"x86_64": "linuxx86-64", "arm64": "linuxarm64"}
    build_types = {"release": "", "debug": "debug"}

    for comp_name, comp_info in desired_versions_data["wpi_libs"]["components"].items():
        print(f"\n  Processing WPILib {comp_name} v{wpi_version}")

        # Handle binary downloads
        for arch_key, arch_classifier in architectures.items():
            for build_type_key, build_type_classifier in build_types.items():
                classifier_suffix = f"{arch_classifier}{build_type_classifier}"
                binary_url = comp_info["binary_url_template"].format(
                    base_maven_url=wpi_base_maven_url,
                    group_id_path=comp_info["group_id_path"],
                    artifact_id=comp_info["artifact_id"],
                    version=wpi_version,
                    classifier=classifier_suffix,
                )
                filename = (
                    f"{comp_info['artifact_id']}-{wpi_version}-{classifier_suffix}.zip"
                )
                download_path = os.path.join(temp_download_dir, filename)
                fetch_name = comp_info["fetch_name_template"].format(
                    arch=arch_key, type=build_type_key
                )

                try:
                    if download_file(binary_url, download_path):
                        binary_hash = calculate_sha256(download_path)
                        desired_versions_data["hashes"][fetch_name] = {
                            "url": binary_url,
                            "hash": binary_hash,
                        }
                        print(f"    {fetch_name} hash: {binary_hash}")
                except requests.exceptions.RequestException as e:
                    print(f"    Error fetching {fetch_name}: {e}")
                    sys.exit(1)
                except Exception as e:
                    print(f"    An unexpected error occurred for {fetch_name}: {e}")
                    sys.exit(1)

        # Handle header downloads
        headers_url = comp_info["headers_url_template"].format(
            base_maven_url=wpi_base_maven_url,
            group_id_path=comp_info["group_id_path"],
            artifact_id=comp_info["artifact_id"],
            version=wpi_version,
        )
        headers_filename = f"{comp_info['artifact_id']}-{wpi_version}-headers.zip"
        headers_download_path = os.path.join(temp_download_dir, headers_filename)
        headers_fetch_name = comp_info["headers_fetch_name"]

        try:
            if download_file(headers_url, headers_download_path):
                headers_hash = calculate_sha256(headers_download_path)
                desired_versions_data["hashes"][headers_fetch_name] = {
                    "url": headers_url,
                    "hash": headers_hash,
                }
                print(f"    {headers_fetch_name} hash: {headers_hash}")
        except requests.exceptions.RequestException as e:
            print(f"    Error fetching {headers_fetch_name}: {e}")
            sys.exit(1)
        except Exception as e:
            print(f"    An unexpected error occurred for {headers_fetch_name}: {e}")
            sys.exit(1)

    # --- Final Steps ---
    print("\n--- Finalizing Update ---")

    # Save updated versions.json (contains all calculated hashes)
    with open(versions_json_file, "w") as f:
        json.dump(desired_versions_data, f, indent=2)
    print(f"Updated {versions_json_file} with new hashes.")

    # Generate versions.cmake from the updated data
    generate_cmake_versions_file(desired_versions_data, cmake_versions_file)

    shutil.rmtree(temp_download_dir)
    print(f"Cleaned up temporary directory: {temp_download_dir}")

    print("\nDependency update process completed.")
    print(
        "Remember to 'git add' and 'git commit' the updated versions.json and versions.cmake files."
    )


if __name__ == "__main__":
    main()
